{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0209b74-e12e-4cfe-8113-2f16f96f4938",
   "metadata": {},
   "source": [
    "Eraste Boko"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d05bdd-e53e-4b63-8627-62313b2ad21c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Machine Learning: Multilayer Perceptron Regression\n",
    "\n",
    "Neural Networks for Regression Tasks\n",
    "\n",
    "Dataset: Housing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad61136f-829d-4a07-a70c-82b59c333aa6",
   "metadata": {},
   "source": [
    "#### •Import the data from the provided “housing.csv” file and pre-process it by applying one hot encoding to replace the categorical features with binary features and by replacing NaN values with the mean value from that column. Do not apply feature expansion; this is a technique we  use when trying to supply our linear models with additional data but not\n",
    "#### neural networks. For a neural network, we will attempt other solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b957529-dbb1-4ffb-851c-8ef07da6116e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bbe6415-1cb6-4975-b54d-579f158861cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Multilayer Perceptron Regression package\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6123904-5e4a-40f4-b74a-5ccde70895fb",
   "metadata": {},
   "source": [
    "#### • Create your training and test set based on your cleansed and pre-processed data. Use this same training and test data consistently in all of your experiments.\n",
    "#### • As a first attempt at building a model, create and train a multilayer perceptron neural network using its default values to try to predict the median house value. Here and throughout your notebook, after you fit your model to the training data, print out the model’s accuracy on both the training set and the test set.\n",
    "#### Remember to increase the “max_iter” parameter from the default if needed and that, here and throughout, models that do not converge should be treated as failed runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92ed8920-4a3c-4f29-a017-8aae875e9f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = pd.read_csv(\"housing.csv\")\n",
    "housing_input = housing.drop(\"median_house_value\", axis=1)\n",
    "housing_output = housing[\"median_house_value\"].copy()\n",
    "encoded_input = pd.get_dummies(housing_input)\n",
    "cleaned_input = encoded_input.fillna(encoded_input.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8303d504-66cc-4780-a549-26b6c02412e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_input shape:  (20640, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>ocean_proximity_&lt;1H OCEAN</th>\n",
       "      <th>ocean_proximity_INLAND</th>\n",
       "      <th>ocean_proximity_ISLAND</th>\n",
       "      <th>ocean_proximity_NEAR BAY</th>\n",
       "      <th>ocean_proximity_NEAR OCEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms   \n",
       "0    -122.23     37.88                41.0        880.0           129.0  \\\n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  ocean_proximity_<1H OCEAN   \n",
       "0       322.0       126.0         8.3252                      False  \\\n",
       "1      2401.0      1138.0         8.3014                      False   \n",
       "2       496.0       177.0         7.2574                      False   \n",
       "3       558.0       219.0         5.6431                      False   \n",
       "4       565.0       259.0         3.8462                      False   \n",
       "\n",
       "   ocean_proximity_INLAND  ocean_proximity_ISLAND  ocean_proximity_NEAR BAY   \n",
       "0                   False                   False                      True  \\\n",
       "1                   False                   False                      True   \n",
       "2                   False                   False                      True   \n",
       "3                   False                   False                      True   \n",
       "4                   False                   False                      True   \n",
       "\n",
       "   ocean_proximity_NEAR OCEAN  \n",
       "0                       False  \n",
       "1                       False  \n",
       "2                       False  \n",
       "3                       False  \n",
       "4                       False  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"cleaned_input shape: \", cleaned_input.shape)\n",
    "encoded_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38b9a53b-6d62-46c5-bb66-f3e3f94eee51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:  0.6935422269035172\n",
      "Accuracy on test set:  0.6826178247440557\n"
     ]
    }
   ],
   "source": [
    "# create a multilayer perceptron regressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(cleaned_input, housing_output, random_state=42)\n",
    "mlp = MLPRegressor(max_iter=3000,random_state=42)\n",
    "\n",
    "# fit the regressor to the training data\n",
    "mlp.fit(X_train, y_train)\n",
    "\n",
    "# print its accuracy on the training set\n",
    "print(\"Accuracy on training set: \", mlp.score(X_train, y_train))\n",
    "\n",
    "# print its accuracy on the test set\n",
    "print(\"Accuracy on test set: \", mlp.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8b195c-b191-4bbd-9569-6116f950f244",
   "metadata": {},
   "source": [
    "#### •Next, rescale your features so they all have a mean of 0 and a variance of 1. Create and train a new MLPRegressor model. Observe that, even with a reasonably large value for “max_iter”, your model is unlikely to converge now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d42e6cc9-ba0c-49ff-81f1-a1fd6533ec2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the mean value for each feature of the training set\n",
    "mean_on_train = X_train.mean(axis=0)\n",
    "\n",
    "# compute the standard deviation for each feature of the training set\n",
    "std_on_train = X_train.std(axis=0)\n",
    "\n",
    "# apply the same transformation to both the training and test set\n",
    "X_train_scaled = (X_train - mean_on_train)/std_on_train\n",
    "X_test_scaled = (X_test - mean_on_train)/std_on_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53bda71e-afb4-4b41-9007-38b48c2e11f2",
   "metadata": {},
   "source": [
    "#### •Review the scikit learn documentation at https://scikit-learn.org/ for the MLPRegressor model and observe that the default MLPRegressor has a single hidden layer of 100 units. In order to train a neural network of this shape to learn our data, it is likely that you will need to experiment with both the “alpha” regularization factor (which we have worked with in class) \n",
    "#### and the “learning_rate_init” parameter (which is new to this assignment). Check the documentation for the default values for both of these parameters and identify a setting for both of these parameters, as well as the “max_iter” parameter that does allow convergence.\n",
    "#### Note that randomly changing these values will not be as effective as researching and making sure you understand the role of these parameters and then considering what changes may help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab8d5c7d-62b7-47d3-a171-622f44626489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:  0.8243325520752796\n",
      "Accuracy on test set:  0.7936743196561722\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPRegressor(max_iter=6000,alpha=0.001,learning_rate_init=0.01, hidden_layer_sizes=[90,105], random_state=42)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: \", mlp.score(X_train_scaled, y_train))\n",
    "print(\"Accuracy on test set: \", mlp.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5f0c242-b97a-4046-84e5-c0edc56813f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:  0.8255529122847771\n",
      "Accuracy on test set:  0.7892249972588324\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPRegressor(max_iter=6000,alpha=0.001,learning_rate_init=0.01, hidden_layer_sizes=[90,105,5], random_state=42)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: \", mlp.score(X_train_scaled, y_train))\n",
    "print(\"Accuracy on test set: \", mlp.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9575bce2-90d9-4498-90f0-10a602c8cae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:  0.8107744409240205\n",
      "Accuracy on test set:  0.7839434760860771\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPRegressor(max_iter=6000,alpha=0.001,learning_rate_init=0.01, hidden_layer_sizes=[80,105,4], random_state=42)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: \", mlp.score(X_train_scaled, y_train))\n",
    "print(\"Accuracy on test set: \", mlp.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e479549-8a4c-4b0b-a30d-bedc08244dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:  0.820708366360485\n",
      "Accuracy on test set:  0.7919947526400402\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPRegressor(max_iter=6000,alpha=0.001,learning_rate_init=0.01, hidden_layer_sizes=[90,105,6], random_state=42)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Accuracy on training set: \", mlp.score(X_train_scaled, y_train))\n",
    "print(\"Accuracy on test set: \", mlp.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7886b3-78ac-4b5e-92c9-3f21ed9c3798",
   "metadata": {},
   "source": [
    "#### • Proceed to experiment with the following possible changes to the shape of your neural network. Start by using the values for the max_iter, learning_rate_init and alpha parameters that you have found allow you to reach convergence for a default network with a single layer of 100 hidden units, but make adjustments as needed to be able to convince\n",
    "#### yourself you understand whether these different neural network shapes produce better quality models or not.\n",
    "#### o Maintain a single hidden layer and explore the impact of increasing or decreasing the number of units in that single layer.\n",
    "#### o Add a second hidden layer and explore the impact of having a larger first layer versus a smaller first layer and how many units seem to be needed in these layers.\n",
    "#### o Explore whether adding a third hidden layer can be used to improve the quality of the learned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb16dca2-0a9a-46a9-9a5b-f40f72084f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter=[3000, 5000, 8000, 10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2472433c-d44d-4d36-9933-a1880b4bbe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=[0.001, 0.01, 0.1, 1, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e4cc842-af4e-49c0-9511-dcca07989153",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_init=[ 0.01, 0.1, 1, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2e545f7-dc38-4a47-a94b-32f023a3a096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_iter: 3000\n",
      "Accuracy on training set:  0.8255529122847771\n",
      "Accuracy on test set:  0.7892249972588324\n",
      "\n",
      "max_iter: 5000\n",
      "Accuracy on training set:  0.8255529122847771\n",
      "Accuracy on test set:  0.7892249972588324\n",
      "\n",
      "max_iter: 8000\n",
      "Accuracy on training set:  0.8255529122847771\n",
      "Accuracy on test set:  0.7892249972588324\n",
      "\n",
      "max_iter: 10000\n",
      "Accuracy on training set:  0.8255529122847771\n",
      "Accuracy on test set:  0.7892249972588324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for mi in max_iter:\n",
    "    mlp = MLPRegressor(max_iter=mi,alpha=0.001,learning_rate_init=0.01, hidden_layer_sizes=[90,105,5], random_state=42)\n",
    "    mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "    train_accuracy = mlp.score(X_train_scaled, y_train)\n",
    "    test_accuracy = mlp.score(X_test_scaled, y_test)\n",
    "    print(\"max_iter:\", mi)\n",
    "    print(\"Accuracy on training set: \", mlp.score(X_train_scaled, y_train))\n",
    "    print(\"Accuracy on test set: \", mlp.score(X_test_scaled, y_test)) \n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cab46ff6-7d78-4533-abc4-55594e1dd0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.001\n",
      "Accuracy on training set:  0.8255529122847771\n",
      "Accuracy on test set:  0.7892249972588324\n",
      "\n",
      "alpha: 0.01\n",
      "Accuracy on training set:  0.8166510868001509\n",
      "Accuracy on test set:  0.7790189458213668\n",
      "\n",
      "alpha: 0.1\n",
      "Accuracy on training set:  0.8249492733280843\n",
      "Accuracy on test set:  0.7902282537508376\n",
      "\n",
      "alpha: 1\n",
      "Accuracy on training set:  0.8415514292417421\n",
      "Accuracy on test set:  0.7973070278159309\n",
      "\n",
      "alpha: 10\n",
      "Accuracy on training set:  0.8206360215971069\n",
      "Accuracy on test set:  0.7889406347016861\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for a in alpha:\n",
    "    mlp = MLPRegressor(max_iter=6000,alpha=a,learning_rate_init=0.01, hidden_layer_sizes=[90,105,5], random_state=42)\n",
    "    mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "\n",
    "    train_accuracy = mlp.score(X_train_scaled, y_train)\n",
    "    test_accuracy = mlp.score(X_test_scaled, y_test)\n",
    "    print(\"alpha:\", a)\n",
    "    print(\"Accuracy on training set: \", mlp.score(X_train_scaled, y_train))\n",
    "    print(\"Accuracy on test set: \", mlp.score(X_test_scaled, y_test)) \n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d203cebc-1748-4feb-906d-dea5e4905770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning_rate_init: 0.01\n",
      "Accuracy on training set:  0.8255529122847771\n",
      "Accuracy on test set:  0.7892249972588324\n",
      "\n",
      "learning_rate_init: 0.1\n",
      "Accuracy on training set:  0.7046575622896709\n",
      "Accuracy on test set:  0.6959159502863956\n",
      "\n",
      "learning_rate_init: 1\n",
      "Accuracy on training set:  0.7921353634682831\n",
      "Accuracy on test set:  0.7707740659436444\n",
      "\n",
      "learning_rate_init: 10\n",
      "Accuracy on training set:  -2.844117497069476e-08\n",
      "Accuracy on test set:  -4.09134355552343e-05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for lri  in learning_rate_init:\n",
    "    mlp = MLPRegressor(max_iter=6000,alpha=0.001,learning_rate_init=lri, hidden_layer_sizes=[90,105,5], random_state=42)\n",
    "    mlp.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    train_accuracy = mlp.score(X_train_scaled, y_train)\n",
    "    test_accuracy = mlp.score(X_test_scaled, y_test)\n",
    "    print(\"learning_rate_init:\", lri)\n",
    "    print(\"Accuracy on training set: \", mlp.score(X_train_scaled, y_train))\n",
    "    print(\"Accuracy on test set: \", mlp.score(X_test_scaled, y_test)) \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56788b4d-cff2-4762-8104-599ba571307e",
   "metadata": {},
   "source": [
    "#### •Based on your experiments, pick the neural network shape that produces the best model overall, avoiding both overfitting and underfitting. Experiment more comprehensively with the values for the max_iter, learning_rate_init, and alpha parameters until you are convinced you have the best quality model you can train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "098d4c07-31bd-4c92-b703-96c64414f0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha2=[1, 2,3,4,5,6,7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4a2d422-744b-49bd-bafe-3fac24bbffff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 1\n",
      "Accuracy on training set:  0.8208644570998662\n",
      "Accuracy on test set:  0.7901836552577707\n",
      "\n",
      "alpha: 2\n",
      "Accuracy on training set:  0.819174585698654\n",
      "Accuracy on test set:  0.7895282653558293\n",
      "\n",
      "alpha: 3\n",
      "Accuracy on training set:  0.8045266237932318\n",
      "Accuracy on test set:  0.7732788678345154\n",
      "\n",
      "alpha: 4\n",
      "Accuracy on training set:  0.8061784512661796\n",
      "Accuracy on test set:  0.7713286821973875\n",
      "\n",
      "alpha: 5\n",
      "Accuracy on training set:  0.8200300085210637\n",
      "Accuracy on test set:  0.7900751136114335\n",
      "\n",
      "alpha: 6\n",
      "Accuracy on training set:  0.8247760809543074\n",
      "Accuracy on test set:  0.7915920365469766\n",
      "\n",
      "alpha: 7\n",
      "Accuracy on training set:  0.8005236845683075\n",
      "Accuracy on test set:  0.7708984327717952\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for a in alpha2:\n",
    "    mlp = MLPRegressor(max_iter=6000,alpha=a,learning_rate_init=0.01, hidden_layer_sizes=[90,105,6], random_state=42)\n",
    "    mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # print out the accuracy on the training and test sets, remembering to\n",
    "    # use the scaled versions here as well\n",
    "    train_accuracy = mlp.score(X_train_scaled, y_train)\n",
    "    test_accuracy = mlp.score(X_test_scaled, y_test)\n",
    "    print(\"alpha:\", a)\n",
    "    print(\"Accuracy on training set: \", mlp.score(X_train_scaled, y_train))\n",
    "    print(\"Accuracy on test set: \", mlp.score(X_test_scaled, y_test)) \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7036c80-ce2e-4b34-833f-2681a600d015",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha3=[0.00001, 0.000001,0.000001,0.0000001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c69d54e-1000-4663-8374-530a4e4cc0c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 1e-05\n",
      "Accuracy on training set:  0.8132655096258569\n",
      "Accuracy on test set:  0.7890547446508376\n",
      "\n",
      "alpha: 1e-06\n",
      "Accuracy on training set:  0.8225003075177546\n",
      "Accuracy on test set:  0.792106400985379\n",
      "\n",
      "alpha: 1e-06\n",
      "Accuracy on training set:  0.8225003075177546\n",
      "Accuracy on test set:  0.792106400985379\n",
      "\n",
      "alpha: 1e-07\n",
      "Accuracy on training set:  0.8244733677665421\n",
      "Accuracy on test set:  0.7918937681622842\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for a in alpha3:\n",
    "    mlp = MLPRegressor(max_iter=6000,alpha=a,learning_rate_init=0.01, hidden_layer_sizes=[90,105,5], random_state=42)\n",
    "    mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "    # print out the accuracy on the training and test sets, remembering to\n",
    "    # use the scaled versions here as well\n",
    "    train_accuracy = mlp.score(X_train_scaled, y_train)\n",
    "    test_accuracy = mlp.score(X_test_scaled, y_test)\n",
    "    print(\"alpha:\", a)\n",
    "    print(\"Accuracy on training set: \", mlp.score(X_train_scaled, y_train))\n",
    "    print(\"Accuracy on test set: \", mlp.score(X_test_scaled, y_test)) \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5254bc4b-734d-4e09-9d6b-58567653132d",
   "metadata": {},
   "source": [
    "#### The neural network shape that produces the best model overall avoiding both overfitting and underfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7013538c-7629-4f1e-af05-5e1f4055f67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:  0.8415514292417421\n",
      "Accuracy on test set:  0.7973070278159309\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPRegressor(max_iter=6000,alpha=1,learning_rate_init=0.01, hidden_layer_sizes=[90,105,5], random_state=42)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "# print out the accuracy on the training and test sets, remembering to\n",
    "# use the scaled versions here as well\n",
    "print(\"Accuracy on training set: \", mlp.score(X_train_scaled, y_train))\n",
    "print(\"Accuracy on test set: \", mlp.score(X_test_scaled, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
